"""Tests for baseline models."""

import numpy as np
import pytest

from fyp.baselines.anomaly import (
    DecompositionAnomalyDetector,
    StatisticalAnomalyDetector,
    create_default_detectors,
    detect_anomaly_events,
)
from fyp.baselines.forecasting import (
    SeasonalNaive,
    LinearTrendForecaster,
    create_default_forecasters,
)
from fyp.metrics import (
    mean_absolute_error,
    root_mean_squared_error,
    forecasting_metrics,
    anomaly_metrics,
    MetricsTracker,
)


def create_synthetic_sine_data(n_points: int = 144, noise_level: float = 0.1) -> np.ndarray:
    """Create synthetic sine wave data with noise."""
    t = np.linspace(0, 6 * np.pi, n_points)  # 3 full cycles
    data = 2 + np.sin(t) + np.sin(2 * t) * 0.5  # Daily + sub-daily pattern
    data += np.random.normal(0, noise_level, n_points)  # Add noise
    return np.maximum(data, 0)  # Ensure non-negative


def create_synthetic_data_with_anomalies(n_points: int = 144) -> tuple[np.ndarray, np.ndarray]:
    """Create synthetic data with known anomalies."""
    data = create_synthetic_sine_data(n_points, noise_level=0.05)
    labels = np.zeros(n_points)
    
    # Inject spikes as anomalies
    anomaly_indices = [30, 60, 90, 120]
    for idx in anomaly_indices:
        if idx < n_points:
            data[idx] *= 3  # Create spike
            labels[idx] = 1
    
    return data, labels


class TestForecasting:
    """Test forecasting models."""
    
    def test_seasonal_naive(self):
        """Test seasonal naive forecaster."""
        data = create_synthetic_sine_data(96)  # 2 days at 30-min resolution
        
        forecaster = SeasonalNaive(seasonal_period=48)
        forecaster.fit(data)
        
        # Forecast next day
        forecast = forecaster.predict(data, steps=48)
        
        assert len(forecast) == 48
        assert all(f >= 0 for f in forecast)  # Non-negative forecasts
        
        # Should repeat pattern from previous day
        expected = data[-48:]
        mae = mean_absolute_error(expected, forecast)
        assert mae < 1.0  # Should be close to exact repeat
    
    def test_linear_trend_forecaster(self):
        """Test linear trend forecaster."""
        # Create trending data
        t = np.arange(96)
        data = 1 + 0.01 * t + np.sin(2 * np.pi * t / 48) * 0.5
        
        forecaster = LinearTrendForecaster(include_trend=True)
        forecaster.fit(data)
        
        # Forecast
        forecast = forecaster.predict(data, steps=24)
        
        assert len(forecast) == 24
        assert all(f >= 0 for f in forecast)
        
        # Should capture trend
        assert forecast[-1] > forecast[0]  # Trending up
    
    def test_create_default_forecasters(self):
        """Test default forecaster creation."""
        forecasters = create_default_forecasters()
        
        assert "seasonal_naive" in forecasters
        assert "linear_trend" in forecasters
        assert "ensemble" in forecasters
        
        # Test they can all be fitted and used
        data = create_synthetic_sine_data(96)
        
        for name, forecaster in forecasters.items():
            forecaster.fit(data)
            forecast = forecaster.predict(data, steps=12)
            assert len(forecast) == 12


class TestAnomalyDetection:
    """Test anomaly detection models."""
    
    def test_decomposition_detector(self):
        """Test decomposition-based anomaly detector."""
        data, labels = create_synthetic_data_with_anomalies(144)
        
        # Split train/test
        train_data = data[:96]
        test_data = data[96:]
        test_labels = labels[96:]
        
        detector = DecompositionAnomalyDetector(seasonal_period=48)
        detector.fit(train_data)
        
        scores = detector.predict_scores(test_data)
        
        assert len(scores) == len(test_data)
        assert all(s >= 0 for s in scores)
        
        # Should detect at least some variation in scores
        assert np.max(scores) > 0 or np.std(scores) > 0
    
    def test_statistical_detector(self):
        """Test statistical anomaly detector."""
        data, labels = create_synthetic_data_with_anomalies(144)
        
        train_data = data[:96]
        test_data = data[96:]
        
        detector = StatisticalAnomalyDetector(window_size=24)
        detector.fit(train_data)
        
        scores = detector.predict_scores(test_data)
        
        assert len(scores) == len(test_data)
        assert all(s >= 0 for s in scores)
    
    def test_detect_anomaly_events(self):
        """Test anomaly event detection."""
        scores = np.array([0.1, 0.8, 0.9, 0.7, 0.2, 0.1, 0.9, 0.1])
        
        events = detect_anomaly_events(scores, threshold=0.5, min_duration=1)
        
        assert len(events) >= 1
        assert all("start" in event for event in events)
        assert all("end" in event for event in events)
        assert all("duration" in event for event in events)
    
    def test_create_default_detectors(self):
        """Test default detector creation."""
        detectors = create_default_detectors()
        
        assert "decomposition" in detectors
        assert "statistical" in detectors
        assert "ensemble" in detectors
        
        # Test they can all be fitted and used
        data = create_synthetic_sine_data(96)
        
        for name, detector in detectors.items():
            detector.fit(data)
            scores = detector.predict_scores(data[:48])
            assert len(scores) == 48


class TestMetrics:
    """Test metrics calculations."""
    
    def test_basic_forecasting_metrics(self):
        """Test basic forecasting metrics."""
        y_true = np.array([1.0, 2.0, 3.0, 4.0])
        y_pred = np.array([1.1, 1.9, 3.1, 3.9])
        
        mae = mean_absolute_error(y_true, y_pred)
        rmse = root_mean_squared_error(y_true, y_pred)
        
        assert abs(mae - 0.1) < 1e-10
        assert abs(rmse - 0.1) < 1e-10
    
    def test_forecasting_metrics_comprehensive(self):
        """Test comprehensive forecasting metrics."""
        y_true = np.array([1.0, 2.0, 3.0, 4.0])
        y_pred = np.array([1.1, 1.9, 3.1, 3.9])
        y_train = np.array([0.5, 1.5, 2.5, 3.5])
        
        metrics = forecasting_metrics(y_true, y_pred, y_train)
        
        assert "mae" in metrics
        assert "rmse" in metrics
        assert "mape" in metrics
        assert "mase" in metrics
        
        assert all(v >= 0 for v in metrics.values())
    
    def test_anomaly_metrics(self):
        """Test anomaly detection metrics."""
        y_true = np.array([0, 0, 1, 1, 0])
        y_scores = np.array([0.1, 0.2, 0.8, 0.9, 0.15])
        
        metrics = anomaly_metrics(y_true, y_scores, threshold=0.5)
        
        assert "precision" in metrics
        assert "recall" in metrics
        assert "f1" in metrics
        
        assert 0 <= metrics["precision"] <= 1
        assert 0 <= metrics["recall"] <= 1
        assert 0 <= metrics["f1"] <= 1
    
    def test_metrics_tracker(self):
        """Test metrics tracking and aggregation."""
        tracker = MetricsTracker()
        
        # Add some forecasting results
        for i in range(3):
            y_true = np.random.rand(10)
            y_pred = y_true + np.random.normal(0, 0.1, 10)
            
            tracker.add_forecasting_result(
                entity_id=f"entity_{i}",
                window_id=i,
                y_true=y_true,
                y_pred=y_pred,
            )
        
        summary = tracker.get_forecasting_summary()
        
        assert "avg_mae" in summary
        assert "n_windows" in summary
        assert summary["n_windows"] == 3
        
        # Add anomaly results
        for i in range(2):
            y_true = np.random.choice([0, 1], 50)
            y_scores = np.random.rand(50)
            
            tracker.add_anomaly_result(
                entity_id=f"entity_{i}",
                y_true=y_true,
                y_scores=y_scores,
            )
        
        anomaly_summary = tracker.get_anomaly_summary()
        
        assert "avg_precision" in anomaly_summary
        assert "n_entities" in anomaly_summary
        assert anomaly_summary["n_entities"] == 2


class TestIntegration:
    """Integration tests with synthetic data."""
    
    def test_end_to_end_forecasting(self):
        """Test end-to-end forecasting pipeline."""
        # Create multi-seasonal data
        data = create_synthetic_sine_data(144, noise_level=0.1)
        
        # Split into history and target
        history = data[:96]
        target = data[96:]
        
        # Test all forecasters
        forecasters = create_default_forecasters()
        
        results = {}
        for name, forecaster in forecasters.items():
            forecaster.fit(history)
            forecast = forecaster.predict(history, steps=len(target))
            
            mae = mean_absolute_error(target, forecast)
            results[name] = mae
        
        # All should produce reasonable forecasts
        assert all(mae < 2.0 for mae in results.values())
        
        # Ensemble should be competitive
        assert results["ensemble"] <= max(results.values())
    
    def test_end_to_end_anomaly_detection(self):
        """Test end-to-end anomaly detection pipeline."""
        data, labels = create_synthetic_data_with_anomalies(144)
        
        # Split train/test
        train_data = data[:96]
        test_data = data[96:]
        test_labels = labels[96:]
        
        # Test all detectors
        detectors = create_default_detectors()
        
        results = {}
        for name, detector in detectors.items():
            detector.fit(train_data)
            scores = detector.predict_scores(test_data)
            
            # Simple threshold-based evaluation
            pred_labels = (scores > 0.5).astype(int)
            precision = np.sum((pred_labels == 1) & (test_labels == 1)) / (np.sum(pred_labels) + 1e-8)
            
            results[name] = precision
        
        # Should detect some anomalies correctly
        assert any(p > 0 for p in results.values())
